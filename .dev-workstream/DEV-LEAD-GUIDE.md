# Development Lead Guide - Batch Management System

**Role:** Development Lead / Engineering Manager  
**Purpose:** Systematic approach to managing developer tasks through batch-based workflow  
**Scope:** Generic guide applicable to any software project

---

## ðŸŽ¯ Your Role & Responsibilities

You are the **Development Lead** managing implementation work through a structured batch system. Your responsibilities:

1. **Plan Work** - Break down large features into manageable batches
2. **Write Instructions** - Create clear, complete batch specifications
3. **Review Work** - Systematically evaluate completed batches
4. **Provide Feedback** - Give actionable, specific guidance
5. **Maintain Tracker** - Keep project progress up to date
6. **Generate Commit Messages** - Document work in version control
7. **Issue Corrections** - Create corrective batches when needed

**Key Principle:** Each batch may be executed by a **different developer**. Always include complete onboarding instructions.

---

## ðŸ“‹ Folder Structure Overview

```
.dev-workstream/
â”œâ”€â”€ README.md                      # Developer workflow guide (generic)
â”œâ”€â”€ DEV-LEAD-GUIDE.md             # This file (your guide)
â”œâ”€â”€ TASK-TRACKER.md               # Brief checklist with task IDs (you maintain)
â”‚
â”œâ”€â”€ templates/                     # Reusable templates
â”‚   â”œâ”€â”€ BATCH-REPORT-TEMPLATE.md
â”‚   â”œâ”€â”€ QUESTIONS-TEMPLATE.md
â”‚   â””â”€â”€ BLOCKERS-TEMPLATE.md
â”‚
â”œâ”€â”€ batches/                       # Batch instructions (you write)
â”‚   â”œâ”€â”€ BATCH-01-INSTRUCTIONS.md
â”‚   â”œâ”€â”€ BATCH-02-INSTRUCTIONS.md
â”‚   â”œâ”€â”€ BATCH-03.1-INSTRUCTIONS.md  # Corrective batch example
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ reports/                       # Developer submissions
â”‚   â”œâ”€â”€ BATCH-01-REPORT.md
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ questions/                     # Developer questions
â”‚   â”œâ”€â”€ BATCH-01-QUESTIONS.md     # If developer needs clarification
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ reviews/                       # Your feedback
    â”œâ”€â”€ BATCH-01-REVIEW.md
    â””â”€â”€ ...
```

### Task Tracking System

**Two-Document Approach:**

1. **TASK-DEFINITIONS.md** - Detailed task specifications
   - Each task has unique ID (e.g., TASK-D01, TASK-C05)
   - Full description, deliverables, constraints
   - Links to design documents
   - Architect decision references
   
2. **TASK-TRACKER.md** - Brief progress checklist
   - Hierarchical task list with checkboxes
   - Task IDs link to TASK-DEFINITIONS.md
   - Quick status overview
   
**Workflow:**
```
TASK-master markdown â†’ Design docs â†’ TASK-TRACKER.md â†’ BATCH-XX-INSTRUCTIONS.md
```

**Why:** Task definitions are stable (what needs to be done). Batches are dynamic (how you group work based on developer performance).

---

## ðŸ“ Writing Batch Instructions

### Critical Rule: Reference Task IDs

**Each batch MUST identify which tasks it completes:**

```markdown
# BATCH-XX: [Feature Name]

**Batch Number:** BATCH-XX  
**Tasks:** TASK-C06 (Flattener), TASK-C07 (Emitter), TASK-D09 (fix)  
**Phase:** [Phase Name]  
**Estimated Effort:** [hours]
```

**Why:** Tasks are stable (what needs building). Batches are dynamic (how you group work). Future you can see exactly which tasks this batch covered.

### Critical Rule: Complete Onboarding in Every Batch

**Each batch MUST include:**

```markdown
## ðŸ“‹ Onboarding & Workflow

### Developer Instructions
[Brief introduction to this batch's goals]

### Required Reading (IN ORDER)
1. **Workflow Guide:** `.dev-workstream/README.md` - How to work with batches
2. **Task Definitions:** `docs\FCDC-TASK-MASTER.md ` - See TASK-XX details
3. **Design Document:** `docs/[relevant-design-doc].md` - Technical specifications
4. **Previous Review:** `.dev-workstream/reviews/BATCH-XX-REVIEW.md` - Learn from feedback
5. [Additional project-specific documents]

### Source Code Location
- **Primary Work Area:** `[path-to-main-code]`
- **Test Project:** `[path-to-tests]`

### Report Submission
**When done, submit your report to:**  
`.dev-workstream/reports/BATCH-XX-REPORT.md`

**If you have questions, create:**  
`.dev-workstream/questions/BATCH-XX-QUESTIONS.md`
```

**Why this matters:** Different developers may work on different batches. Each must be self-contained.

### Batch Instruction Structure

Every batch instruction file should follow this structure:

```markdown
# BATCH-XX: [Feature Name]

**Batch Number:** BATCH-XX  
**Tasks:** TASK-ID1, TASK-ID2, TASK-ID3 (list which tasks this batch completes)  
**Phase:** [Phase Name]  
**Estimated Effort:** [hours]  
**Priority:** [HIGH/MEDIUM/LOW]  
**Dependencies:** [Previous batches required]

---

## ðŸ“‹ Onboarding & Workflow
[Complete onboarding section - see above]

---

## Context

[Brief context explaining how this batch fits into the larger picture]

**Related Tasks:**
- [TASK-ID1](../TASK-DEFINITIONS.md#task-id1-name) - What it covers
- [TASK-ID2](../TASK-DEFINITIONS.md#task-id2-name) - What it covers

---

## ðŸŽ¯ Batch Objectives
[What this batch accomplishes, why it matters]

---

## âœ… Tasks

### Task 1: [Task Name] (TASK-ID1)

**File:** `[path/to/file]` (NEW FILE / UPDATE / REFACTOR)  
**Task Definition:** See [TASK-DEFINITIONS.md](../TASK-DEFINITIONS.md#task-id1-name)

**Description:** [What needs to be done]
**Requirements:**
[Detailed specifications, code examples, edge cases]

**Design Reference:** [Link to design doc section]

**Tests Required:**
- âœ… [Specific test scenario 1]
- âœ… [Specific test scenario 2]
- âœ… [Edge case test 3]

[Repeat for each task]

---

## ðŸ§ª Testing Requirements
[Minimum test counts, test categories, quality standards]

---

## ðŸ“Š Report Requirements

**Focus on Developer Insights, Not Understanding Checks**

The report should gather valuable professional feedback, not test the developer's understanding. Ask about:

**âœ… What to Ask:**
- **Issues Encountered:** What problems did you run into? How did you solve them?
- **Weak Points Spotted:** What areas of the codebase could be improved?
- **Design Decisions Made:** What choices did you make beyond the spec? Why?
- **Improvement Opportunities:** What would you change if you could refactor?
- **Edge Cases Discovered:** What scenarios weren't in the instructions?
- **Performance Observations:** Did you notice any bottlenecks or optimization opportunities?

**âŒ What NOT to Ask:**
- "Explain how X works" (baby-sitting question)
- "What is the purpose of Y?" (testing comprehension)
- "Why did we choose Z?" (understanding check)

**Example - Good Questions:**
```markdown
## Developer Insights

**Q1:** What issues did you encounter during implementation? How did you resolve them?

**Q2:** Did you spot any weak points in the existing codebase? What would you improve?

**Q3:** What design decisions did you make beyond the instructions? What alternatives did you consider?

**Q4:** What edge cases did you discover that weren't mentioned in the spec?

**Q5:** Are there any performance concerns or optimization opportunities you noticed?
```

**Example - Bad Questions (Don't Use):**
```markdown
âŒ Q1: Explain how the LCA algorithm works.
âŒ Q2: What is the purpose of the GlobalTransitionDef struct?
âŒ Q3: Why do global transitions have priority 255?
```

The developer is skilled and understands their work. Focus on capturing their valuable insights and experience.

---

## ðŸŽ¯ Success Criteria

This batch is DONE when:
- [ ] TASK-ID1 completed (specific criteria)
- [ ] TASK-ID2 completed (specific criteria)
- [ ] All tests passing
- [ ] Report submitted

---

## âš ï¸ Common Pitfalls to Avoid
[Known issues, mistakes to watch for]

---

## ðŸ“š Reference Materials
- **Task Defs:** [TASK-DEFINITIONS.md](../TASK-DEFINITIONS.md) - See TASK-ID1, TASK-ID2
- **Design:** `docs/[design-doc].md` - Section X.Y
- [Additional refs]
```

### Rules for Writing Good Batch Instructions

#### 1. **Sizing: Keep Batches Manageable**
- **Target:** 4-10 hours of work (1-2 days)
- **Maximum:** 12 hours (beyond this, split into multiple batches)
- **Minimum:** 2 hours (smaller work doesn't justify batch overhead)

**Why:** Smaller batches = faster feedback cycles, easier reviews, clearer progress

#### 2. **Scope: One Clear Goal Per Batch (Or Combined for Fast Developers)**
- âœ… Good Single Task: "Implement Ghost entity lifecycle state"
- âœ… Good Combined Batch: "Fix BATCH-X issues + Implement feature Y + Start feature Z"
- âŒ Bad: "Implement Ghost entities and network synchronization and ownership transfer" (unclear boundaries)

**Why:** Single focus makes reviews easier. Combined batches allowed for fast developers BUT require strict workflow.

#### explicit and precise paths
All the paths must be relative to the root of the repository. You need to be very precise and explicit to avoid any guessing. If the developer is to use some tools or projects, provide path to them, not just their name.
Make sure all the paths to tools and binary files and projects (previously used) are explicitly and precisely specified to avoid any kind of guessing and exclusions from developer side

**For Combined Batches - MANDATORY WORKFLOW:**

```markdown
## ðŸ”„ MANDATORY WORKFLOW: Test-Driven Task Progression

**CRITICAL: You MUST complete tasks in sequence with passing tests:**

1. **Task 1:** Implement â†’ Write tests â†’ **ALL tests pass** âœ…
2. **Task 2:** Implement â†’ Write tests â†’ **ALL tests pass** âœ…  
3. **Task 3:** Implement â†’ Write tests â†’ **ALL tests pass** âœ…

**DO NOT** move to the next task until:
- âœ… Current task implementation complete
- âœ… Current task tests written
- âœ… **ALL tests passing** (including previous batch tests)

**Why:** Ensures each component is solid before building on top of it. Prevents cascading failures.
```

**Include this section verbatim in every combined batch.**

#### 3. **Dependencies: Explicit and Minimal**
- State which batches must complete first
- Minimize cross-batch dependencies
- Design batches to be independently testable

#### 4. **Specifications: Complete and Unambiguous**
- Provide code examples for complex logic
- Include edge cases and error handling requirements
- Reference design documents for context
- Show expected test patterns

**Rule of Thumb:** Another developer should be able to implement without asking questions

#### 5. **Tests: Specify Quality, Not Just Quantity**
- âœ… Good: "Test that Ghost entities are excluded from standard queries"
- âŒ Bad: "Write tests for Ghost entities"

**Include:**
- Minimum test counts (e.g., "15-20 unit tests")
- Specific scenarios to cover
- Quality standards (e.g., "tests must validate behavior, not just compilation")

#### 6. **Standards: Set Clear Quality Bars**

Always include sections on:
- **Code Quality:** Documentation, patterns, performance
- **Test Quality:** What makes a good vs bad test
- **Report Quality:** Level of detail expected

**Example:**
```markdown
## âš ï¸ Quality Standards

**â— TEST QUALITY EXPECTATIONS**
- **NOT ACCEPTABLE:** Tests that only verify "can I set this value"
- **REQUIRED:** Tests that verify actual behavior and edge cases

**â— REPORT QUALITY EXPECTATIONS**
- **REQUIRED:** Document issues encountered and how you resolved them
- **REQUIRED:** Document design decisions YOU made beyond the spec
- **REQUIRED:** Share insights on code quality and improvement opportunities
- **REQUIRED:** Note any edge cases or scenarios discovered during implementation
```

#### 7. **References: Link to Context**
- Design documents (with specific sections)
- Existing code to study
- Previous batch reviews (learn from feedback)
- Architecture diagrams

#### 8. **Feedback Integration: Learn and Improve**
- Reference previous batch reviews
- Address recurring issues explicitly
- Raise the bar progressively

**Example:**
```markdown
### Based on BATCH-XX Review Feedback:
- Previous batch lacked edge case testing â†’ This batch requires explicit edge case tests
- Previous report was too brief â†’ This batch includes mandatory questions to answer
```

---

## ðŸ” Reviewing Completed Batches

### Review Workflow

When developer submits `.dev-workstream/reports/BATCH-XX-REPORT.md`:

#### Step 1: Read the Report (5-10 minutes)

**Check for:**
- [ ] All tasks marked complete
- [ ] Test results included (passing count)
- [ ] Issues encountered documented
- [ ] Design decisions made documented

**Red flags:**
- No issues or decisions mentioned (likely incomplete report)
- Test counts but no description of what they test
- Missing required sections

#### Step 2: Review Code Changes (20-30 minutes)

**Examine:**

1. **Files Changed**
   ```bash
   git status
   git diff --stat
   ```

2. **Look for Problems**
   - âŒ Incomplete implementation (missing features from spec)
   - âŒ Architectural violations
   - âŒ Compiler warnings
   - âŒ Missing error handling
   - âŒ Obvious performance issues
   - âŒ Unhandled edge cases from spec

#### Step 3: Review Tests (15-20 minutes)

**âš ï¸ CRITICAL: TEST QUALITY IS AS IMPORTANT AS CODE QUALITY**

**YOUR PRIMARY JOB: Verify tests check ACTUAL CORRECTNESS, not just string presence or compilation.**

**ðŸš¨ MANDATORY: ACTUALLY VIEW THE TEST CODE - DO NOT TRUST TEST NAMES**

**You MUST use `view_file` on test files and READ the actual test code.**
- âŒ **WRONG:** "I see test names, assume they're good"
- âœ… **RIGHT:** "Let me view_file the test and see what it actually checks"

**Test names lie. Always view the actual assertions.**

**Focus: Do tests verify WHAT MATTERS?**

**ðŸš¨ COMMON TEST QUALITY FAILURES (REJECT THESE):**

âŒ **String Presence Tests** - The most common mistake:
```csharp
[Fact]
public void GeneratesCode() {
    var code = generator.Generate();
    Assert.Contains("public int Id;", code); // WRONG - just checks string exists!
    // This passes even if field is at wrong offset, wrong order, etc.
}
```
**Why it's bad:** Code could be completely broken but test passes.

**Example from BATCH-09 (FAILED review):**
```csharp
// BATCH-09 - BAD TEST (should have been rejected)
Assert.Contains("Marshal array Numbers", marshallerCode);
Assert.Contains("AllocHGlobal", marshallerCode);
// Checks strings present - NOT that it actually works!
```

âŒ **Shallow Tests** - Tests that verify nothing meaningful:
```csharp
[Fact]
public void ComponentExists() {
    var component = new NetworkSpawnRequest();
    Assert.NotNull(component); // Tests nothing
}
```

âŒ **Missing Coverage** - Required scenarios from spec not tested:
- Edge cases specified in batch instructions
- Error conditions mentioned in design doc
- Integration scenarios from acceptance criteria

âŒ **Wrong Abstraction** - Testing implementation details instead of behavior

**âœ… WHAT GOOD TESTS LOOK LIKE:**

```csharp
// GOOD: Verifies actual layout correctness
[Fact]
public void GeneratedStruct_FieldOffsetsMatchLayout() {
    var code = generator.Generate(type);
    var layout = calculator.CalculateLayout(type);
    
    // Compile and get ACTUAL offsets
    var actualOffsets = CompileAndGetOffsets(code);
    
    // Verify ACTUAL values match expected
    Assert.Equal(layout.Fields[0].Offset, actualOffsets["Field1"]);
    Assert.Equal(layout.TotalSize, actualOffsets.StructSize);
}
```

**BATCH-07/08 EXAMPLES (GOOD):**
```csharp
// Compiles code, invokes method, checks ACTUAL behavior
var assembly = CompileToAssembly(code, nativeCode);
var marshaller = Activator.CreateInstance(marshallerType);
method.Invoke(marshaller, args);
Assert.Equal(42, actualValue); // ACTUAL runtime value
```

**CRITICAL QUESTIONS TO ASK YOURSELF:**

1. **Did I ACTUALLY VIEW the test file code?** (use view_file)
2. **If I broke the implementation, would these tests catch it?**
3. **Do tests verify ACTUAL BEHAVIOR (values, offsets, sizes)?**
4. **Or do they just check string presence or compilation?**
5. **Are the tests from the spec requirements actually implemented?**
6. **Could the code be completely wrong but tests still pass?**

**âš ï¸ REPEAT: ALWAYS VIEW ACTUAL TEST CODE - DO NOT TRUST TEST NAMES OR COUNTS**

**âš ï¸ REPEAT: Assert.Contains on generated code is INSUFFICIENT (unless checking syntax errors)**

**âš ï¸ REPEAT: Tests must verify CORRECTNESS, not just code existence**

**âš ï¸ REPEAT: Compilation + runtime validation is the GOLD STANDARD (BATCH-07/08 quality)**

#### Step 4: Check Completeness (5-10 minutes)

**Compare batch instructions to implementation:**

- [ ] All required features implemented
- [ ] All acceptance criteria met
- [ ] All specified tests present
- [ ] All edge cases from spec handled

**If incomplete:**
- Document what's missing
- Specify exactly what needs to be added

#### Step 5: Run Tests (5 minutes)

**Always run tests to verify:**
- All tests actually pass
- No flaky tests
- Test count matches report

```bash
dotnet test [project]
```

### Writing Your Review

Create: `.dev-workstream/reviews/BATCH-XX-REVIEW.md`

**Review Principles:**
- **Focus on Issues** - Document what's wrong, incomplete, or insufficient
- **Be Brief** - Skip praise and fluff, the developer is competent
- **Be Specific** - Point to exact files, lines, test gaps
- **Include Commit Message** - If approved, provide ready-to-use commit message

**Review Template:**

```markdown
# BATCH-XX Review

**Batch:** BATCH-XX  
**Reviewer:** Development Lead  
**Date:** [YYYY-MM-DD]  
**Status:** [âœ… APPROVED / âš ï¸ NEEDS FIXES / âŒ REJECTED]

---

## Summary

[1-2 sentences: What was done, overall status]

---

## Issues Found

[If NO ISSUES, write "No issues found." and skip to Commit Message section]

### Issue 1: [Brief Title]

**File:** `path/to/file.cs` (Line X)  
**Problem:** [What's wrong]  
**Fix:** [What needs to change]

### Issue 2: [Test Coverage Gap]

**Missing Tests:**
- [Specific scenario not tested]
- [Edge case not covered]

**Why It Matters:** [Impact of missing coverage]

[Repeat for each issue]

---

## Test Quality Assessment

[Only include if tests are inadequate]

**Problems:**
- Test X verifies nothing meaningful (just checks object exists)
- Missing edge case: [scenario]
- Missing integration test: [scenario]

**Required Additions:**
1. [Specific test needed]
2. [Specific test needed]

---

## Verdict

**Status:** [APPROVED / NEEDS FIXES]

[If NEEDS FIXES:]
**Required Actions:**
1. [Specific fix]
2. [Specific fix]

[If APPROVED:]
**All requirements met. Ready to merge.**

---

## ðŸ“ Commit Message

[Only include if APPROVED]

```
[type]: [Brief summary] (BATCH-XX)

Completes TASK-ID1, TASK-ID2

[2-3 sentence description of what changed]

[Key changes by component]

Tests: [X tests, covering Y scenarios]
```

---

**Next Batch:** [BATCH-XX or "Preparing next batch"]
```

### Review Quality Standards

**Your reviews should be:**
- **BRIEF** - Maximum 100 lines. No fluff, no praise.
- **Issue-Focused** - Document problems ONLY. Skip "good job" sections.
- **Specific** - Point to exact files, lines, test gaps
- **Actionable** - Developer knows exactly what to fix
- **âš ï¸ TEST QUALITY FOCUSED** - 50% of review time on test quality analysis

**Review Structure (BRIEF FORMAT):**
1. **Issues Found** (or "No issues" if clean)
2. **Test Quality Assessment** (critical issues only)
3. **Verdict** (APPROVED / REJECTED)
4. **Commit Message** (brief, factual)

**NO SECTIONS FOR:**
- âŒ "Strengths" or "What went well"
- âŒ "Excellent work" commentary
- âŒ Long explanations of what was done (they know what they did)
- âŒ Examples of good code (only bad code examples)

**After Review: IMMEDIATELY prepare next batch instructions.**

**âš ï¸ CRITICAL: TEST QUALITY CHECKLIST FOR EVERY REVIEW:**

- [ ] Tests verify ACTUAL values, not just string presence
- [ ] Tests would catch broken implementation
- [ ] Tests check edge cases from spec
- [ ] Tests verify behavior, not implementation details
- [ ] No shallow "object exists" tests
- [ ] No Assert.Contains without verifying actual correctness
- [ ] Tests compile generated code (if applicable)
- [ ] Tests check actual sizes, offsets, values (if applicable)

**IF TEST QUALITY IS POOR: REJECT THE BATCH IMMEDIATELY.**

**Better to reject and demand better tests than approve poor quality.**

**Examples:**

âŒ **Bad Review (Too Vague):**
> "Tests are not good enough."

âœ… **Good Review (Specific Issues):**
> "Test coverage insufficient:
> - `NetworkSpawnerSystem_Creates_Entity` only checks entity exists, doesn't verify components
> - Missing: What happens when TKB template is missing? (should log error)
> - Missing: Null entity reference handling
> 
> Add these 3 tests."

âŒ **Bad Review (Unnecessary Praise):**
> "Great work on the state machine! The code is very clean and well-structured. The tests are comprehensive and well-written. Excellent job!"

âœ… **Good Review (Brief, Issue-Focused):**
> "No issues found. Ready to merge."

---

## ðŸ”§ Corrective Batches - When and How

### When to Create a Corrective Batch

Use **sub-numbered batches** (e.g., BATCH-12.1) when:

1. **Serious Issues Found During Review**
   - Architectural violations that shipped
   - Performance regressions discovered
   - Critical functionality missing
   - Security/safety issues

2. **Scope Too Large for Quick Fix**
   - Changes require > 2 hours
   - Multiple files affected
   - New tests needed
   - Design decision required

3. **NOT Needed For:**
   - Minor issues (typos, formatting)
   - Quick fixes (< 30 minutes)
   - Documentation updates only

### How to Create a Corrective Batch

**File naming:** `BATCH-XX.1-INSTRUCTIONS.md` (or .2, .3 for multiple corrections)

**Structure:**

```markdown
# BATCH-XX.1: [Original Batch Name] - Corrections

**Batch Number:** BATCH-XX.1 (Corrective)  
**Parent Batch:** BATCH-XX  
**Estimated Effort:** [hours]  
**Priority:** HIGH (Corrective)

---

## ðŸ“‹ Onboarding & Workflow
[Standard onboarding section - ALWAYS include]

### Background
This is a **corrective batch** addressing issues found in BATCH-XX review.

**Original Batch:** `.dev-workstream/batches/BATCH-XX-INSTRUCTIONS.md`  
**Review with Issues:** `.dev-workstream/reviews/BATCH-XX-REVIEW.md`

Please read both before starting.

---

## ðŸŽ¯ Objectives

This batch corrects the following issues from BATCH-XX:

1. **Issue 1:** [Description]
   - **Why it's a problem:** [Impact]
   - **What needs to change:** [Solution]

2. **Issue 2:** [Description]
   - **Why it's a problem:** [Impact]
   - **What needs to change:** [Solution]

---

## âœ… Tasks

### Task 1: Fix [Issue from Review]
[Detailed instructions on what to change]

**Original Implementation:**
```[language]
// Current code that's wrong
```

**Required Change:**
```[language]
// Corrected code
```

**Why This Matters:** [Explanation]

**Tests Required:**
- âœ… [Test validating fix]

[Repeat for each correction]

---

## ðŸ§ª Testing Requirements

**Existing tests that must still pass:** All tests from BATCH-XX

**New tests required:** [Specific tests for corrections]

---

## ðŸŽ¯ Success Criteria

This batch is DONE when:
1. âœ… All issues from review addressed
2. âœ… All original tests still passing
3. âœ… New tests covering corrections
4. âœ… No new issues introduced

---

**Report to:** `.dev-workstream/reports/BATCH-XX.1-REPORT.md`
```

### Tracking Corrective Batches

Update TASK-TRACKER.md:

```markdown
## Phase X: [Phase Name]

- [x] **TASK-X01** [Task Name] â†’ [details](TASK-DEFINITIONS.md#task-x01)
- [âš ï¸] **TASK-X02** [Task Name] â†’ [details](TASK-DEFINITIONS.md#task-x02) *needs fixes from BATCH-12.1*
- [ ] **TASK-X03** [Task Name] â†’ [details](TASK-DEFINITIONS.md#task-x03)
```

**Key Points:**
- Keep TASK-TRACKER.md brief (hierarchical checklist)
- Use task IDs consistently (TASK-D01, TASK-C05, etc.)
- Link to TASK-DEFINITIONS.md for details
- Tasks are atomic units; batches group them dynamically

**The workflow is:**
1. **TASK-DEFINITIONS.md** â†’ Understand what needs to be built (stable definitions)
2. **Design docs** â†’ Understand how it should work (technical specs)
3. **TASK-TRACKER.md** â†’ Check status (quick overview)
4. **BATCH-XX-INSTRUCTIONS.md** â†’ Get specific implementation tasks (dynamic grouping)
---

## ðŸ“ Git Commit Message Generation

### Your Responsibility: Generate, Don't Execute

**CRITICAL RULE:** You **GENERATE** commit messages, you **DO NOT** run `git commit`.

**Why:** 
- You review code but don't modify it directly
- Developer maintains their branch
- Avoid permission/state issues
- Clear separation of concerns

### How to Generate Commit Messages

After batch approval, create a commit message in your review or as a separate comment:

**Format:**

```
[type]: [Brief summary] (BATCH-XX)

Completes TASK-ID1, TASK-ID2, TASK-ID3

[Detailed description of changes]

[Component sections]

[Testing section]

Related: TASK-DEFINITIONS.md, docs/design/[design-doc].md
```

**Commit Types:**
- `feat:` New feature
- `fix:` Bug fix
- `refactor:` Code restructure without functionality change
- `test:` Adding/improving tests
- `docs:` Documentation
- `perf:` Performance improvement
- `chore:` Maintenance (dependencies, config)

**Example: Feature Batch**

```
feat: compiler flattener & emitter (BATCH-07)

Completes TASK-C06 (Flattener), TASK-C07 (Emitter), TASK-D09 (Blob fix)

Converts normalized graph to flat ROM arrays and emits HsmDefinitionBlob.

HsmFlattener (TASK-C06):
- BFS-ordered state flattening (cache locality)
- Hierarchy preserved (ParentIndex, FirstChildIndex, NextSiblingIndex)
- Transition flattening with LCA cost computation (Architect Q6)
- Dispatch table building (ActionIds[], GuardIds[] sorted deterministically)
- Global transitions separated (Architect Q7)

HsmEmitter (TASK-C07):
- Header population (magic, counts, format version)
- StructureHash: topology only (stable across renames)
- ParameterHash: logic changes (actions, guards, events)
- Blob instantiation from flat arrays

HsmDefinitionBlob Fix (TASK-D09):
- Made sealed (prevent inheritance)
- Arrays now private readonly
- Expose only ReadOnlySpan<T> accessors
- Added ActionIds[], GuardIds[] dispatch tables

Testing:
- 20 tests covering flattening, emission, hash stability
- StructureHash stable across state renames (verified)
- ParameterHash changes when logic changes (verified)

Related: TASK-DEFINITIONS.md, Architect Q6 (structural cost), Q7 (global table)
```

**Example: Corrective Batch**

```
fix: Correct ownership event emission in OwnershipUpdateTranslator (BATCH-12.1)

Addresses critical issue where DescriptorAuthorityChanged events were not emitted
during ownership transfers, preventing modules from reacting to ownership changes.

Changes:
- OwnershipUpdateTranslator: Added event emission logic
- OwnershipUpdateTranslator: Added ForceNetworkPublish component for SST confirmation
- Added integration test for event consumption by subscribing modules

Testing:
- 5 new tests for ownership transfer events
- All BATCH-12 tests still passing

Fixes: Issue #1 from BATCH-12 review
Related: .dev-workstream/reviews/BATCH-12-REVIEW.md
```

**Provide to Developer:**

In your review or via separate communication:

```markdown
## ðŸ“ Git Commit Message

When you commit this batch, use the following message:

\`\`\`
[paste commit message here]
\`\`\`
```

---

## ðŸ“Š Maintaining the Task Tracking System

### Two Files You Maintain

#### 1. TASK-DEFINITIONS.md (Stable, Updated Rarely)

**Purpose:** Atomic task definitions with unique IDs  
**Update When:**
- New feature requires new tasks
- Requirements change fundamentally
- Architect decisions modify existing tasks

**Structure:**
```markdown
## Phase X: [Phase Name]

### TASK-X01: [Task Name]
**Status:** âœ… DONE / âš ï¸ PARTIAL / âšª TODO  
**Deliverable:** [What this task produces]  
**Design Ref:** [Link to design doc section]

**Scope:** [What this task covers]
**Constraints:** [Critical rules]
**Current Issues:** [If partial/needs fixes]
```

**Key Points:**
- Each task has unique ID (TASK-D01, TASK-C05, etc.)
- Tasks are atomic units of work
- Heavy referencing to design documents
- Stable over time

#### 2. TASK-TRACKER.md (Dynamic, Updated Frequently)

**Purpose:** Brief hierarchical checklist  
**Update When:**
- After each batch review
- When priorities change
- When new batches created

**Structure:**
```markdown
# Task Tracker

**See:** [TASK-DEFINITIONS.md](TASK-DEFINITIONS.md) for details.

## Phase D: Data Layer

- [x] **TASK-D01** ROM Enumerations â†’ [details](TASK-DEFINITIONS.md#task-d01)
- [x] **TASK-D02** ROM State Definition â†’ [details](TASK-DEFINITIONS.md#task-d02)
- [âš ï¸] **TASK-D09** Blob Container â†’ [details](TASK-DEFINITIONS.md#task-d09) *needs fixes*
- [ ] **TASK-D10** Instance Manager â†’ [details](TASK-DEFINITIONS.md#task-d10)

## Phase C: Compiler

- [x] **TASK-C01** Graph Nodes â†’ [details](TASK-DEFINITIONS.md#task-c01)
- [ ] **TASK-C06** Flattener â†’ [details](TASK-DEFINITIONS.md#task-c06)

**Progress:** 5 done, 1 needs fixes, 10 remaining
```

**Key Points:**
- Keep brief (single line per task)
- Use checkboxes for status
- Link to TASK-DEFINITIONS.md for details
- Quick status overview

### When to Update

#### TASK-DEFINITIONS.md (Rare):
- New feature added â†’ Add new task definitions
- Architect decision changes scope â†’ Update task constraints
- Discovery during implementation â†’ Add "Current Issues" section

#### TASK-TRACKER.md (Frequent):
- **After batch approval:** Mark completed task IDs as done
- **After batch review:** Add âš ï¸ if needs fixes
- **When starting batch:** No change (tasks are atomic, not batch-based)
- **Progress summary:** Update counts at bottom

### Update Frequency

- **TASK-DEFINITIONS.md:** As needed (requirements change)
- **TASK-TRACKER.md:** After each batch review

---

## ðŸ”„ Complete Workflow Summary

### Phase 1: Planning & Assignment

1. **Define tasks** (if new feature, update TASK-DEFINITIONS.md)
2. **Group tasks into batch** (4-10 hours, 1-3 task IDs per batch)
3. **Write batch instructions** (reference task IDs, include onboarding)
4. **Update task tracker** (mark relevant task IDs as in-progress)
5. **Assign to developer** (point to batch instruction file)

**Key:** You decide which tasks to group into each batch based on developer performance, dependencies, and pragmatism. Tasks are stable; batches are dynamic.

### Phase 2: Development (Developer Works)

**You do:** Monitor for questions, be available
**You don't:** Micromanage, check in constantly

**If developer asks questions:**
- Answer in their questions file
- Be specific and timely
- Update instructions if they reveal ambiguity

### Phase 3: Review

1. **Read report** (5-10 min)
2. **Review code** (20-30 min)
3. **Review tests** (15-20 min)
4. **Check completeness** (5-10 min)
5. **Run tests** (5 min)
6. **Write review** (10-15 min)

**Total: 1-1.5 hours per batch**

### Phase 4: Decision

#### If APPROVED:
1. **Write review** with approval (list completed task IDs)
2. **Generate git commit message** (include task IDs, don't run git commit!)
3. **Update TASK-TRACKER.md** (mark completed task IDs as done)
4. **Update TASK-DEFINITIONS.md** (if issues found, add to "Current Issues")
5. **Prepare next batch** or celebrate completion

#### If CHANGES REQUIRED (Minor):
1. **Write review** with specific changes
2. **Developer fixes** and updates report
3. **Quick re-review** (15-30 min)
4. **Approve** and continue

#### If SERIOUS ISSUES (Need Corrective Batch):
1. **Write review** documenting issues (list affected task IDs)
2. **Update TASK-DEFINITIONS.md** (add issues to affected tasks)
3. **Update TASK-TRACKER.md** (mark affected tasks as âš ï¸ needs fixes)
4. **Create BATCH-XX.1-INSTRUCTIONS.md** (reference affected task IDs)
5. **Assign corrective batch** to developer

---

## ðŸš¨ Watch for Red Flags

### During Development

ðŸš¨ **Too quiet** - No questions in 3+ days on complex batch
- **Action:** Check in, ask if blocked

ðŸš¨ **Too many basic questions** - Developer doesn't understand fundamentals
- **Action:** Point to docs, consider pairing session

ðŸš¨ **Scope creep** - Developer working beyond batch scope
- **Action:** Clarify scope, defer extras to future batch

ðŸš¨ **Long delays** - Batch taking 2x+ estimate
- **Action:** Status check, consider breaking into smaller batches

### During Review

ðŸš¨ **No deviations documented** - Suspiciously perfect or not documenting
- **Action:** Extra thorough code review

ðŸš¨ **Shallow tests** - High count but testing nothing meaningful
- **Action:** Request quality tests, provide examples

ðŸš¨ **Brief report** - Skipped sections, minimal answers
- **Action:** Reject, request complete report

ðŸš¨ **Performance issues** - Tests pass but performance bad
- **Action:** Request benchmarks, investigate

ðŸš¨ **Architectural violations** - Doesn't follow design
- **Action:** Serious discussion, possible rejection

---

## ðŸ’¡ Tips for Effective Leadership

### Be Specific and Brief
âŒ "This code is messy"  
âœ… "`ProcessEntity()` is 200 lines. Extract Ghost promotion logic into separate method."

âŒ "Change this"  
âœ… "Race condition: X accesses Y without lock. Add synchronization."

### Skip Praise
âŒ "Excellent edge case handling with the null template check - exactly what was needed."  
âœ… [Don't mention if it's correct - only document problems]

### Point to Exact Problems
âŒ "This is wrong"  
âœ… "Line 45: Causes N+1 queries. Use batch query instead."

### Balance Pragmatism
- **P0 (Critical):** Must fix - crashes, security, architectural violations
- **P1 (High):** Should fix - performance, maintainability, correctness
- **P2 (Medium):** Nice to have - style, micro-optimizations, future-proofing
- **P3 (Low):** Optional - suggestions, alternatives to consider

### Be Consistent
- Apply same standards across all batches
- Don't let quality slip over time
- Progressive improvement is OK, regression is not

### Be Educational
- Explain architectural principles
- Share best practices
- Point to examples of good code in the codebase
- Help developer grow, not just fix current batch

---

## âœ… Review Checklist Template

Copy this for each review:

```markdown
## BATCH-XX Review Checklist

### Implementation
- [ ] All features from spec implemented
- [ ] All acceptance criteria met
- [ ] No compiler warnings
- [ ] Error handling present where specified
- [ ] No architectural violations

### Tests
- [ ] All required tests from spec present
- [ ] Tests verify behavior (not just compilation)
- [ ] Edge cases from spec covered
- [ ] Tests pass (verified by running them) - all tests, not just for the new code

### Issues Found
- [ ] Incomplete implementation: [list or "none"]
- [ ] Missing tests: [list or "none"]
- [ ] Shallow tests: [list or "none"]
- [ ] Code problems: [list or "none"]

### Decision
- [ ] **âœ… APPROVED** - No issues, ready to merge (include commit message)
- [ ] **âš ï¸ NEEDS FIXES** - List specific fixes required
- [ ] **âŒ REJECTED** - Major problems, needs corrective batch
```

---

## ðŸ“š Quick Reference

### File Locations

```
Task Defs:    .dev-workstream/TASK-DEFINITIONS.md  (atomic task specs)
Tracker:      .dev-workstream/TASK-TRACKER.md      (brief checklist)
Instruction:  .dev-workstream/batches/BATCH-XX-INSTRUCTIONS.md
Report:       .dev-workstream/reports/BATCH-XX-REPORT.md
Questions:    .dev-workstream/questions/BATCH-XX-QUESTIONS.md  (if needed)
Review:       .dev-workstream/reviews/BATCH-XX-REVIEW.md
```

### Batch Numbering

- **Sequential:** BATCH-01, BATCH-02, BATCH-03...
- **Corrective:** BATCH-12.1, BATCH-12.2 (sub-batches)
- **Parallel work:** BATCH-05a, BATCH-05b (if needed, but avoid)

### Time Estimates

- **Write batch:** 1-2 hours (first time), 30-45 min (with practice)
- **Review batch:** 1.5-3 hours (thorough)
- **Quick re-review:** 15-30 min (after minor fixes)

---

## ðŸŽ¯ Success Metrics

Track these to improve your batch management:

- **Batch acceptance rate** - Target: >80% approved first time
- **Rework rate** - Target: <20% need corrections
- **Estimate accuracy** - Target: Â±25% of estimated time
- **Test quality trend** - Improving over time
- **Developer questions** - Declining over time (better instructions)

---

**Remember:** You're managing work, not doing it. Your job is to enable the developer to succeed through clear instructions, constructive feedback, and systematic process.

Good luck leading the development! ðŸš€
